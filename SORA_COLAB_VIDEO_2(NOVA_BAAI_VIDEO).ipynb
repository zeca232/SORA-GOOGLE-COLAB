{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVwwUagvfIjF"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/baaivision/NOVA.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/NOVA/requirements.txt"
      ],
      "metadata": {
        "id": "5Ju6fWKZfMZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/NOVA\n",
        "!pip install -e /content/NOVA/diffnext"
      ],
      "metadata": {
        "id": "2Cqbl-RQfN9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/NOVA"
      ],
      "metadata": {
        "id": "yP9rVe_mfPp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import numpy as np\n",
        "from diffnext.pipelines import NOVAPipeline\n",
        "from PIL import Image\n",
        "import subprocess\n",
        "import tempfile\n",
        "\n",
        "class StreamlinedNOVA:\n",
        "    def __init__(self, model_id, device=\"cuda\"):\n",
        "        self.pipe = NOVAPipeline.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.float16,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "        self.pipe.enable_model_cpu_offload()\n",
        "        self.device = device\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    def generate_frame(self, prompt):\n",
        "        with torch.cuda.amp.autocast():\n",
        "            result = self.pipe(\n",
        "                prompt,\n",
        "                max_latent_length=1,\n",
        "                num_inference_steps=20,\n",
        "                guidance_scale=4.0\n",
        "            ).frames[0]\n",
        "\n",
        "            if isinstance(result, Image.Image):\n",
        "                result = np.array(result)\n",
        "                result = torch.from_numpy(result)\n",
        "            elif not isinstance(result, torch.Tensor):\n",
        "                result = torch.tensor(result)\n",
        "\n",
        "            # Remover dimensões de lote e canal unitário\n",
        "            frame_cpu = result.squeeze().cpu().detach()\n",
        "            torch.cuda.empty_cache()\n",
        "            return frame_cpu\n",
        "\n",
        "    def upscale_frame(self, frame, size=(512, 512)):\n",
        "        if isinstance(frame, torch.Tensor):\n",
        "            frame = frame.squeeze().cpu().numpy()\n",
        "\n",
        "        # Remover dimensões extras (ex: batch)\n",
        "        while frame.ndim > 3:\n",
        "            frame = frame.squeeze(0)\n",
        "\n",
        "        # Converter para (H, W, C)\n",
        "        if frame.ndim == 3 and frame.shape[0] in [1, 3]:\n",
        "            frame = np.transpose(frame, (1, 2, 0))\n",
        "\n",
        "        if frame.ndim == 2:\n",
        "            frame = np.stack([frame] * 3, axis=-1)\n",
        "        elif frame.ndim == 3 and frame.shape[-1] == 1:\n",
        "            frame = np.repeat(frame, 3, axis=-1)\n",
        "\n",
        "        if frame.dtype != np.uint8:\n",
        "            frame = (frame - frame.min()) / (frame.max() - frame.min()) * 255\n",
        "            frame = frame.astype(np.uint8)\n",
        "\n",
        "        img = Image.fromarray(frame)\n",
        "        img = img.resize(size, Image.BILINEAR)\n",
        "        return np.array(img)\n",
        "\n",
        "    def generate_video_ffmpeg(self, prompt, num_frames=50, video_path=\"streamlined_video.mp4\", fps=8, upscale_size=(512, 512)):\n",
        "        temp_dir = tempfile.mkdtemp(prefix=\"temp_frames_\")\n",
        "        saved_frames = []\n",
        "\n",
        "        for i in range(num_frames):\n",
        "            print(f\"Gerando frame {i+1}/{num_frames}\")\n",
        "            try:\n",
        "                frame = self.generate_frame(prompt)\n",
        "                frame_np = self.upscale_frame(frame, upscale_size)\n",
        "                frame_filename = os.path.join(temp_dir, f\"frame_{i:04d}.png\")\n",
        "                Image.fromarray(frame_np).save(frame_filename)\n",
        "                saved_frames.append(frame_filename)\n",
        "            except Exception as e:\n",
        "                print(f\"Erro no frame {i+1}: {str(e)}\")\n",
        "            finally:\n",
        "                del frame, frame_np\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "        if not saved_frames:\n",
        "            raise RuntimeError(\"Nenhum frame foi gerado corretamente.\")\n",
        "\n",
        "        ffmpeg_cmd = [\n",
        "            \"ffmpeg\", \"-y\", \"-framerate\", str(fps),\n",
        "            \"-start_number\", \"0\",\n",
        "            \"-i\", os.path.join(temp_dir, \"frame_%04d.png\"),\n",
        "            \"-c:v\", \"libx264\", \"-pix_fmt\", \"yuv420p\",\n",
        "            video_path\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            subprocess.run(ffmpeg_cmd, check=True)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(\"Erro FFmpeg. Verifique se os frames foram gerados corretamente.\")\n",
        "            raise\n",
        "\n",
        "        # Limpeza\n",
        "        for f in saved_frames:\n",
        "            os.remove(f)\n",
        "        os.rmdir(temp_dir)\n",
        "\n",
        "        return video_path\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_id = \"BAAI/nova-d48w1024-osp480\"\n",
        "    prompt = \"mulher caminhando na cidade\"\n",
        "\n",
        "    streamlined = StreamlinedNOVA(model_id)\n",
        "    video_file = streamlined.generate_video_ffmpeg(prompt, num_frames=50)\n",
        "    print(\"Vídeo salvo em:\", os.path.abspath(video_file))"
      ],
      "metadata": {
        "id": "PGQQVdAEfVsf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}